{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac94476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# this will help in making the Python code more structured automatically (good coding practice)\\n%reload_ext nb_black\\n\\n# Libraries to help with reading and manipulating data\\nimport numpy as np\\nimport pandas as pd\\nimport warnings\\nimport re\\n\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n\\n# Libraries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\nsns.set()\\n\\n\\n# To suppress scientific notations\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n# Removes the limit from the number of displayed columns and rows.\\n# This is so I can see the entire dataframe when I print it\\npd.set_option(\\\"display.max_columns\\\", None)\\n# pd.set_option('display.max_rows', None)\\npd.set_option(\\\"display.max_rows\\\", 200)\\n# change the maximum column width in pandas\\npd.set_option(\\\"max_colwidth\\\", 50)\\n\\n# To check model performance\\n\\nfrom datetime import datetime\\nfrom datetime import timezone\\n\\nimport pylab\\nimport scipy.stats as stats\\n\\n\\nimport statsmodels.stats.api as sms\\nimport statsmodels.api as sm\\nimport statsmodels.stats.api as sms\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\nfrom statsmodels.compat import lzip\\nimport xgboost\\nfrom xgboost import XGBClassifier\\n\\n# To oversample and undersample data\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n\\nfrom sklearn import tree\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn import metrics\\nfrom sklearn import tree\\n\\n# To impute missing values\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n\\nfrom sklearn.model_selection import (\\n    train_test_split,\\n    StratifiedKFold,\\n    cross_val_score,\\n    GridSearchCV,\\n    RandomizedSearchCV,\\n)\\n\\nfrom sklearn.ensemble import (\\n    AdaBoostClassifier,\\n    GradientBoostingClassifier,\\n    StackingClassifier,\\n    BaggingClassifier,\\n    RandomForestClassifier,\\n)\\n\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import (\\n    StandardScaler,\\n    MinMaxScaler,\\n    OneHotEncoder,\\n)\\nfrom datetime import timezone, timedelta\\n\\n\\n# To get diferent metric scores\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    plot_confusion_matrix,\\n    precision_recall_curve,\\n    roc_curve,\\n    make_scorer,\\n    mean_absolute_error,\\n    mean_squared_error,\\n    r2_score,\\n)\";\n",
       "                var nbb_formatted_code = \"# this will help in making the Python code more structured automatically (good coding practice)\\n%reload_ext nb_black\\n\\n# Libraries to help with reading and manipulating data\\nimport numpy as np\\nimport pandas as pd\\nimport warnings\\nimport re\\n\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n\\n# Libraries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\nsns.set()\\n\\n\\n# To suppress scientific notations\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n# Removes the limit from the number of displayed columns and rows.\\n# This is so I can see the entire dataframe when I print it\\npd.set_option(\\\"display.max_columns\\\", None)\\n# pd.set_option('display.max_rows', None)\\npd.set_option(\\\"display.max_rows\\\", 200)\\n# change the maximum column width in pandas\\npd.set_option(\\\"max_colwidth\\\", 50)\\n\\n# To check model performance\\n\\nfrom datetime import datetime\\nfrom datetime import timezone\\n\\nimport pylab\\nimport scipy.stats as stats\\n\\n\\nimport statsmodels.stats.api as sms\\nimport statsmodels.api as sm\\nimport statsmodels.stats.api as sms\\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\\nfrom statsmodels.compat import lzip\\nimport xgboost\\nfrom xgboost import XGBClassifier\\n\\n# To oversample and undersample data\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n\\nfrom sklearn import tree\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn import metrics\\nfrom sklearn import tree\\n\\n# To impute missing values\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n\\nfrom sklearn.model_selection import (\\n    train_test_split,\\n    StratifiedKFold,\\n    cross_val_score,\\n    GridSearchCV,\\n    RandomizedSearchCV,\\n)\\n\\nfrom sklearn.ensemble import (\\n    AdaBoostClassifier,\\n    GradientBoostingClassifier,\\n    StackingClassifier,\\n    BaggingClassifier,\\n    RandomForestClassifier,\\n)\\n\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import (\\n    StandardScaler,\\n    MinMaxScaler,\\n    OneHotEncoder,\\n)\\nfrom datetime import timezone, timedelta\\n\\n\\n# To get diferent metric scores\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    plot_confusion_matrix,\\n    precision_recall_curve,\\n    roc_curve,\\n    make_scorer,\\n    mean_absolute_error,\\n    mean_squared_error,\\n    r2_score,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this will help in making the Python code more structured automatically (good coding practice)\n",
    "%reload_ext nb_black\n",
    "\n",
    "# Libraries to help with reading and manipulating data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Libraries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "\n",
    "# To suppress scientific notations\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "# Removes the limit from the number of displayed columns and rows.\n",
    "# This is so I can see the entire dataframe when I print it\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "# change the maximum column width in pandas\n",
    "pd.set_option(\"max_colwidth\", 50)\n",
    "\n",
    "# To check model performance\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "\n",
    "import pylab\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.compat import lzip\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# To oversample and undersample data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "# To impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    StackingClassifier,\n",
    "    BaggingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "\n",
    "\n",
    "# To be used for data scaling and one hot encoding\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    OneHotEncoder,\n",
    ")\n",
    "from datetime import timezone, timedelta\n",
    "\n",
    "\n",
    "# To get diferent metric scores\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    plot_confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    make_scorer,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "394c387d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"##  Function to calculate different metric scores of the model - Accuracy, Recall and Precision\\ndef get_metrics_score(model, flag=True):\\n    \\\"\\\"\\\"\\n    model : classifier to predict values of X\\n\\n    \\\"\\\"\\\"\\n    # defining an empty list to store train and test results\\n    score_list = []\\n\\n    # Predicting on train and tests\\n    pred_train = model.predict(X_train)\\n    pred_test = model.predict(X_test)\\n\\n    # Accuracy of the model\\n    train_acc = model.score(X_train, y_train)\\n    test_acc = model.score(X_test, y_test)\\n\\n    # Recall of the model\\n    train_recall = metrics.recall_score(y_train, pred_train)\\n    test_recall = metrics.recall_score(y_test, pred_test)\\n\\n    # Precision of the model\\n    train_precision = metrics.precision_score(y_train, pred_train)\\n    test_precision = metrics.precision_score(y_test, pred_test)\\n\\n    score_list.extend(\\n        (\\n            train_acc,\\n            test_acc,\\n            train_recall,\\n            test_recall,\\n            train_precision,\\n            test_precision,\\n        )\\n    )\\n\\n    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\\n    if flag == True:\\n        print(\\\"Accuracy on training set : \\\", model.score(X_train, y_train))\\n        print(\\\"Accuracy on test set : \\\", model.score(X_test, y_test))\\n        print(\\\"Recall on training set : \\\", metrics.recall_score(y_train, pred_train))\\n        print(\\\"Recall on test set : \\\", metrics.recall_score(y_test, pred_test))\\n        print(\\n            \\\"Precision on training set : \\\", metrics.precision_score(y_train, pred_train)\\n        )\\n        print(\\\"Precision on test set : \\\", metrics.precision_score(y_test, pred_test))\\n\\n    return score_list  # returning the list with train and test scores\";\n",
       "                var nbb_formatted_code = \"##  Function to calculate different metric scores of the model - Accuracy, Recall and Precision\\ndef get_metrics_score(model, flag=True):\\n    \\\"\\\"\\\"\\n    model : classifier to predict values of X\\n\\n    \\\"\\\"\\\"\\n    # defining an empty list to store train and test results\\n    score_list = []\\n\\n    # Predicting on train and tests\\n    pred_train = model.predict(X_train)\\n    pred_test = model.predict(X_test)\\n\\n    # Accuracy of the model\\n    train_acc = model.score(X_train, y_train)\\n    test_acc = model.score(X_test, y_test)\\n\\n    # Recall of the model\\n    train_recall = metrics.recall_score(y_train, pred_train)\\n    test_recall = metrics.recall_score(y_test, pred_test)\\n\\n    # Precision of the model\\n    train_precision = metrics.precision_score(y_train, pred_train)\\n    test_precision = metrics.precision_score(y_test, pred_test)\\n\\n    score_list.extend(\\n        (\\n            train_acc,\\n            test_acc,\\n            train_recall,\\n            test_recall,\\n            train_precision,\\n            test_precision,\\n        )\\n    )\\n\\n    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\\n    if flag == True:\\n        print(\\\"Accuracy on training set : \\\", model.score(X_train, y_train))\\n        print(\\\"Accuracy on test set : \\\", model.score(X_test, y_test))\\n        print(\\\"Recall on training set : \\\", metrics.recall_score(y_train, pred_train))\\n        print(\\\"Recall on test set : \\\", metrics.recall_score(y_test, pred_test))\\n        print(\\n            \\\"Precision on training set : \\\", metrics.precision_score(y_train, pred_train)\\n        )\\n        print(\\\"Precision on test set : \\\", metrics.precision_score(y_test, pred_test))\\n\\n    return score_list  # returning the list with train and test scores\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##  Function to calculate different metric scores of the model - Accuracy, Recall and Precision\n",
    "def get_metrics_score(model, flag=True):\n",
    "    \"\"\"\n",
    "    model : classifier to predict values of X\n",
    "\n",
    "    \"\"\"\n",
    "    # defining an empty list to store train and test results\n",
    "    score_list = []\n",
    "\n",
    "    # Predicting on train and tests\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "\n",
    "    # Accuracy of the model\n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "\n",
    "    # Recall of the model\n",
    "    train_recall = metrics.recall_score(y_train, pred_train)\n",
    "    test_recall = metrics.recall_score(y_test, pred_test)\n",
    "\n",
    "    # Precision of the model\n",
    "    train_precision = metrics.precision_score(y_train, pred_train)\n",
    "    test_precision = metrics.precision_score(y_test, pred_test)\n",
    "\n",
    "    score_list.extend(\n",
    "        (\n",
    "            train_acc,\n",
    "            test_acc,\n",
    "            train_recall,\n",
    "            test_recall,\n",
    "            train_precision,\n",
    "            test_precision,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n",
    "    if flag == True:\n",
    "        print(\"Accuracy on training set : \", model.score(X_train, y_train))\n",
    "        print(\"Accuracy on test set : \", model.score(X_test, y_test))\n",
    "        print(\"Recall on training set : \", metrics.recall_score(y_train, pred_train))\n",
    "        print(\"Recall on test set : \", metrics.recall_score(y_test, pred_test))\n",
    "        print(\n",
    "            \"Precision on training set : \", metrics.precision_score(y_train, pred_train)\n",
    "        )\n",
    "        print(\"Precision on test set : \", metrics.precision_score(y_test, pred_test))\n",
    "\n",
    "    return score_list  # returning the list with train and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e575113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def confusion_matrix_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    To plot the confusion_matrix with percentages\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    y_pred = model.predict(predictors)\\n    cm = confusion_matrix(target, y_pred)\\n    labels = np.asarray(\\n        [\\n            [\\\"{0:0.0f}\\\".format(item) + \\\"\\\\n{0:.2%}\\\".format(item / cm.flatten().sum())]\\n            for item in cm.flatten()\\n        ]\\n    ).reshape(2, 2)\\n\\n    plt.figure(figsize=(6, 4))\\n    sns.heatmap(cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\";\n",
       "                var nbb_formatted_code = \"def confusion_matrix_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    To plot the confusion_matrix with percentages\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n    y_pred = model.predict(predictors)\\n    cm = confusion_matrix(target, y_pred)\\n    labels = np.asarray(\\n        [\\n            [\\\"{0:0.0f}\\\".format(item) + \\\"\\\\n{0:.2%}\\\".format(item / cm.flatten().sum())]\\n            for item in cm.flatten()\\n        ]\\n    ).reshape(2, 2)\\n\\n    plt.figure(figsize=(6, 4))\\n    sns.heatmap(cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def confusion_matrix_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    To plot the confusion_matrix with percentages\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(predictors)\n",
    "    cm = confusion_matrix(target, y_pred)\n",
    "    labels = np.asarray(\n",
    "        [\n",
    "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
    "            for item in cm.flatten()\n",
    "        ]\n",
    "    ).reshape(2, 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c31462f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# defining a function to compute different metrics to check performance of a classification model built using sklearn\\ndef model_performance_classification_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check classification model performance\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n\\n    # predicting using the independent variables\\n    pred = model.predict(predictors)\\n\\n    acc = accuracy_score(target, pred)  # to compute Accuracy\\n    recall = recall_score(target, pred)  # to compute Recall\\n    precision = precision_score(target, pred)  # to compute Precision\\n    f1 = f1_score(target, pred)  # to compute F1-score\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\\"Accuracy\\\": acc, \\\"Recall\\\": recall, \\\"Precision\\\": precision, \\\"F1\\\": f1,},\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
       "                var nbb_formatted_code = \"# defining a function to compute different metrics to check performance of a classification model built using sklearn\\ndef model_performance_classification_sklearn(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check classification model performance\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n\\n    # predicting using the independent variables\\n    pred = model.predict(predictors)\\n\\n    acc = accuracy_score(target, pred)  # to compute Accuracy\\n    recall = recall_score(target, pred)  # to compute Recall\\n    precision = precision_score(target, pred)  # to compute Precision\\n    f1 = f1_score(target, pred)  # to compute F1-score\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\\"Accuracy\\\": acc, \\\"Recall\\\": recall, \\\"Precision\\\": precision, \\\"F1\\\": f1,},\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
    "def model_performance_classification_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check classification model performance\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
    "    recall = recall_score(target, pred)  # to compute Recall\n",
    "    precision = precision_score(target, pred)  # to compute Precision\n",
    "    f1 = f1_score(target, pred)  # to compute F1-score\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "913f5664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def getARPFFrame(logitModel,Xvars,Yvars,df=None):\\n    df = pd.DataFrame() if df is None else df\\n    df2= model_performance_classification_statsmodels(logitModel, Xvars, Xvars)\";\n",
       "                var nbb_formatted_code = \"def getARPFFrame(logitModel, Xvars, Yvars, df=None):\\n    df = pd.DataFrame() if df is None else df\\n    df2 = model_performance_classification_statsmodels(logitModel, Xvars, Xvars)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getARPFFrame(logitModel,Xvars,Yvars,df=None):\n",
    "    df = pd.DataFrame() if df is None else df\n",
    "    df2= model_performance_classification_statsmodels(logitModel, Xvars, Xvars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbbed388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"##  Function to calculate recall score\\ndef get_recall_score(model, X_train, X_test, y_train, y_test):\\n    \\\"\\\"\\\"\\n    model : classifier to predict values of X\\n\\n    \\\"\\\"\\\"\\n    pred_train = model.predict(X_train)\\n    pred_test = model.predict(X_test)\\n    print(\\\"Recall on training set : \\\", metrics.recall_score(y_train, pred_train))\\n    print(\\\"Recall on test set : \\\", metrics.recall_score(y_test, pred_test))\";\n",
       "                var nbb_formatted_code = \"##  Function to calculate recall score\\ndef get_recall_score(model, X_train, X_test, y_train, y_test):\\n    \\\"\\\"\\\"\\n    model : classifier to predict values of X\\n\\n    \\\"\\\"\\\"\\n    pred_train = model.predict(X_train)\\n    pred_test = model.predict(X_test)\\n    print(\\\"Recall on training set : \\\", metrics.recall_score(y_train, pred_train))\\n    print(\\\"Recall on test set : \\\", metrics.recall_score(y_test, pred_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##  Function to calculate recall score\n",
    "def get_recall_score(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    model : classifier to predict values of X\n",
    "\n",
    "    \"\"\"\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    print(\"Recall on training set : \", metrics.recall_score(y_train, pred_train))\n",
    "    print(\"Recall on test set : \", metrics.recall_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9018dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# defining a function to plot the confusion_matrix of a classification model\\n\\n\\ndef confusion_matrix_statsmodels(model, predictors, target, threshold=0.5):\\n    \\\"\\\"\\\"\\n    To plot the confusion_matrix with percentages\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    threshold: threshold for classifying the observation as class 1\\n    \\\"\\\"\\\"\\n    y_pred = model.predict(predictors) > threshold\\n    cm = confusion_matrix(target, y_pred)\\n    labels = np.asarray(\\n        [\\n            [\\\"{0:0.0f}\\\".format(item) + \\\"\\\\n{0:.2%}\\\".format(item / cm.flatten().sum())]\\n            for item in cm.flatten()\\n        ]\\n    ).reshape(2, 2)\\n\\n    plt.figure(figsize=(6, 4))\\n    sns.heatmap(cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\\n    print(\\\"*\\\" * 70)\";\n",
       "                var nbb_formatted_code = \"# defining a function to plot the confusion_matrix of a classification model\\n\\n\\ndef confusion_matrix_statsmodels(model, predictors, target, threshold=0.5):\\n    \\\"\\\"\\\"\\n    To plot the confusion_matrix with percentages\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    threshold: threshold for classifying the observation as class 1\\n    \\\"\\\"\\\"\\n    y_pred = model.predict(predictors) > threshold\\n    cm = confusion_matrix(target, y_pred)\\n    labels = np.asarray(\\n        [\\n            [\\\"{0:0.0f}\\\".format(item) + \\\"\\\\n{0:.2%}\\\".format(item / cm.flatten().sum())]\\n            for item in cm.flatten()\\n        ]\\n    ).reshape(2, 2)\\n\\n    plt.figure(figsize=(6, 4))\\n    sns.heatmap(cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\\n    print(\\\"*\\\" * 70)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining a function to plot the confusion_matrix of a classification model\n",
    "\n",
    "\n",
    "def confusion_matrix_statsmodels(model, predictors, target, threshold=0.5):\n",
    "    \"\"\"\n",
    "    To plot the confusion_matrix with percentages\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    threshold: threshold for classifying the observation as class 1\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(predictors) > threshold\n",
    "    cm = confusion_matrix(target, y_pred)\n",
    "    labels = np.asarray(\n",
    "        [\n",
    "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
    "            for item in cm.flatten()\n",
    "        ]\n",
    "    ).reshape(2, 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    print(\"*\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6fb6461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# defining a function to compute different metrics to check performance of a classification model built using statsmodels\\n\\n\\ndef model_performance_classification_statsmodels(\\n    model, predictors, target, threshold=0.5\\n):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check classification model performance\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    threshold: threshold for classifying the observation as class 1\\n    \\\"\\\"\\\"\\n\\n    # checking which probabilities are greater than threshold\\n    pred_temp = model.predict(predictors) > threshold\\n    # rounding off the above values to get classes\\n    pred = np.round(pred_temp)\\n\\n    acc = accuracy_score(target, pred)  # to compute Accuracy\\n    recall = recall_score(target, pred)  # to compute Recall\\n    precision = precision_score(target, pred)  # to compute Precision\\n    f1 = f1_score(target, pred)  # to compute F1-score\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\\"Accuracy\\\": acc, \\\"Recall\\\": recall, \\\"Precision\\\": precision, \\\"F1\\\": f1,},\\n        index=[0],\\n    )\\n    return df_perf\";\n",
       "                var nbb_formatted_code = \"# defining a function to compute different metrics to check performance of a classification model built using statsmodels\\n\\n\\ndef model_performance_classification_statsmodels(\\n    model, predictors, target, threshold=0.5\\n):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check classification model performance\\n\\n    model: classifier\\n    predictors: independent variables\\n    target: dependent variable\\n    threshold: threshold for classifying the observation as class 1\\n    \\\"\\\"\\\"\\n\\n    # checking which probabilities are greater than threshold\\n    pred_temp = model.predict(predictors) > threshold\\n    # rounding off the above values to get classes\\n    pred = np.round(pred_temp)\\n\\n    acc = accuracy_score(target, pred)  # to compute Accuracy\\n    recall = recall_score(target, pred)  # to compute Recall\\n    precision = precision_score(target, pred)  # to compute Precision\\n    f1 = f1_score(target, pred)  # to compute F1-score\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\\"Accuracy\\\": acc, \\\"Recall\\\": recall, \\\"Precision\\\": precision, \\\"F1\\\": f1,},\\n        index=[0],\\n    )\\n    return df_perf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining a function to compute different metrics to check performance of a classification model built using statsmodels\n",
    "\n",
    "\n",
    "def model_performance_classification_statsmodels(\n",
    "    model, predictors, target, threshold=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check classification model performance\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    threshold: threshold for classifying the observation as class 1\n",
    "    \"\"\"\n",
    "\n",
    "    # checking which probabilities are greater than threshold\n",
    "    pred_temp = model.predict(predictors) > threshold\n",
    "    # rounding off the above values to get classes\n",
    "    pred = np.round(pred_temp)\n",
    "\n",
    "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
    "    recall = recall_score(target, pred)  # to compute Recall\n",
    "    precision = precision_score(target, pred)  # to compute Precision\n",
    "    f1 = f1_score(target, pred)  # to compute F1-score\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n",
    "        index=[0],\n",
    "    )\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58306c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Outliers detection using boxplot\\ndef outLierBoxPLot(data):\\n    numerical_col = data.select_dtypes(include=np.number).columns.tolist()\\n    plt.figure(figsize=(25, 40))\\n\\n    for i, variable in enumerate(numerical_col):\\n        plt.subplot(5, 4, i + 1)\\n        plt.boxplot(data[variable], whis=1.5)\\n        plt.tight_layout()\\n        plt.title(variable)\\n\\n    plt.show()\";\n",
       "                var nbb_formatted_code = \"# Outliers detection using boxplot\\ndef outLierBoxPLot(data):\\n    numerical_col = data.select_dtypes(include=np.number).columns.tolist()\\n    plt.figure(figsize=(25, 40))\\n\\n    for i, variable in enumerate(numerical_col):\\n        plt.subplot(5, 4, i + 1)\\n        plt.boxplot(data[variable], whis=1.5)\\n        plt.tight_layout()\\n        plt.title(variable)\\n\\n    plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Outliers detection using boxplot\n",
    "def outLierBoxPLot(data):\n",
    "    numerical_col = data.select_dtypes(include=np.number).columns.tolist()\n",
    "    plt.figure(figsize=(25, 40))\n",
    "\n",
    "    for i, variable in enumerate(numerical_col):\n",
    "        plt.subplot(5, 4, i + 1)\n",
    "        plt.boxplot(data[variable], whis=1.5)\n",
    "        plt.tight_layout()\n",
    "        plt.title(variable)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c5e00d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"### function to plot distributions wrt target\\n\\n\\ndef distribution_plot_wrt_target(data, predictor, target):\\n\\n    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\\n\\n    target_uniq = data[target].unique()\\n\\n    axs[0, 0].set_title(\\\"Distribution of target for target=\\\" + str(target_uniq[0]))\\n    sns.histplot(\\n        data=data[data[target] == target_uniq[0]],\\n        x=predictor,\\n        kde=True,\\n        ax=axs[0, 0],\\n        color=\\\"teal\\\",\\n        stat=\\\"density\\\",\\n    )\\n\\n    axs[0, 1].set_title(\\\"Distribution of target for target=\\\" + str(target_uniq[1]))\\n    sns.histplot(\\n        data=data[data[target] == target_uniq[1]],\\n        x=predictor,\\n        kde=True,\\n        ax=axs[0, 1],\\n        color=\\\"orange\\\",\\n        stat=\\\"density\\\",\\n    )\\n\\n    axs[1, 0].set_title(\\\"Boxplot w.r.t target\\\")\\n    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], palette=\\\"gist_rainbow\\\")\\n\\n    axs[1, 1].set_title(\\\"Boxplot (without outliers) w.r.t target\\\")\\n    sns.boxplot(\\n        data=data,\\n        x=target,\\n        y=predictor,\\n        ax=axs[1, 1],\\n        showfliers=False,\\n        palette=\\\"gist_rainbow\\\",\\n    )\\n\\n    plt.tight_layout()\\n    plt.show()\";\n",
       "                var nbb_formatted_code = \"### function to plot distributions wrt target\\n\\n\\ndef distribution_plot_wrt_target(data, predictor, target):\\n\\n    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\\n\\n    target_uniq = data[target].unique()\\n\\n    axs[0, 0].set_title(\\\"Distribution of target for target=\\\" + str(target_uniq[0]))\\n    sns.histplot(\\n        data=data[data[target] == target_uniq[0]],\\n        x=predictor,\\n        kde=True,\\n        ax=axs[0, 0],\\n        color=\\\"teal\\\",\\n        stat=\\\"density\\\",\\n    )\\n\\n    axs[0, 1].set_title(\\\"Distribution of target for target=\\\" + str(target_uniq[1]))\\n    sns.histplot(\\n        data=data[data[target] == target_uniq[1]],\\n        x=predictor,\\n        kde=True,\\n        ax=axs[0, 1],\\n        color=\\\"orange\\\",\\n        stat=\\\"density\\\",\\n    )\\n\\n    axs[1, 0].set_title(\\\"Boxplot w.r.t target\\\")\\n    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], palette=\\\"gist_rainbow\\\")\\n\\n    axs[1, 1].set_title(\\\"Boxplot (without outliers) w.r.t target\\\")\\n    sns.boxplot(\\n        data=data,\\n        x=target,\\n        y=predictor,\\n        ax=axs[1, 1],\\n        showfliers=False,\\n        palette=\\\"gist_rainbow\\\",\\n    )\\n\\n    plt.tight_layout()\\n    plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### function to plot distributions wrt target\n",
    "\n",
    "\n",
    "def distribution_plot_wrt_target(data, predictor, target):\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "    target_uniq = data[target].unique()\n",
    "\n",
    "    axs[0, 0].set_title(\"Distribution of target for target=\" + str(target_uniq[0]))\n",
    "    sns.histplot(\n",
    "        data=data[data[target] == target_uniq[0]],\n",
    "        x=predictor,\n",
    "        kde=True,\n",
    "        ax=axs[0, 0],\n",
    "        color=\"teal\",\n",
    "        stat=\"density\",\n",
    "    )\n",
    "\n",
    "    axs[0, 1].set_title(\"Distribution of target for target=\" + str(target_uniq[1]))\n",
    "    sns.histplot(\n",
    "        data=data[data[target] == target_uniq[1]],\n",
    "        x=predictor,\n",
    "        kde=True,\n",
    "        ax=axs[0, 1],\n",
    "        color=\"orange\",\n",
    "        stat=\"density\",\n",
    "    )\n",
    "\n",
    "    axs[1, 0].set_title(\"Boxplot w.r.t target\")\n",
    "    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], palette=\"gist_rainbow\")\n",
    "\n",
    "    axs[1, 1].set_title(\"Boxplot (without outliers) w.r.t target\")\n",
    "    sns.boxplot(\n",
    "        data=data,\n",
    "        x=target,\n",
    "        y=predictor,\n",
    "        ax=axs[1, 1],\n",
    "        showfliers=False,\n",
    "        palette=\"gist_rainbow\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c17818a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"### Function to plot stacked bar charts for categorical columns\\ndef stacked_plot(x):\\n    sns.set()\\n    ## crosstab\\n    tab1 = pd.crosstab(x, data[\\\"salary\\\"], margins=True).sort_values(\\n        by=\\\" >50K\\\", ascending=False\\n    )\\n    print(tab1)\\n    print(\\\"-\\\" * 120)\\n    ## visualising the cross tab\\n    tab = pd.crosstab(x, data[\\\"salary\\\"], normalize=\\\"index\\\").sort_values(\\n        by=\\\" >50K\\\", ascending=False\\n    )\\n    tab.plot(kind=\\\"bar\\\", stacked=True, figsize=(17, 7))\\n    plt.legend(\\n        loc=\\\"lower left\\\", frameon=False,\\n    )\\n    plt.legend(loc=\\\"upper left\\\", bbox_to_anchor=(1, 1))\\n    plt.show()\";\n",
       "                var nbb_formatted_code = \"### Function to plot stacked bar charts for categorical columns\\ndef stacked_plot(x):\\n    sns.set()\\n    ## crosstab\\n    tab1 = pd.crosstab(x, data[\\\"salary\\\"], margins=True).sort_values(\\n        by=\\\" >50K\\\", ascending=False\\n    )\\n    print(tab1)\\n    print(\\\"-\\\" * 120)\\n    ## visualising the cross tab\\n    tab = pd.crosstab(x, data[\\\"salary\\\"], normalize=\\\"index\\\").sort_values(\\n        by=\\\" >50K\\\", ascending=False\\n    )\\n    tab.plot(kind=\\\"bar\\\", stacked=True, figsize=(17, 7))\\n    plt.legend(\\n        loc=\\\"lower left\\\", frameon=False,\\n    )\\n    plt.legend(loc=\\\"upper left\\\", bbox_to_anchor=(1, 1))\\n    plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Function to plot stacked bar charts for categorical columns\n",
    "def stacked_plot(x):\n",
    "    sns.set()\n",
    "    ## crosstab\n",
    "    tab1 = pd.crosstab(x, data[\"salary\"], margins=True).sort_values(\n",
    "        by=\" >50K\", ascending=False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 120)\n",
    "    ## visualising the cross tab\n",
    "    tab = pd.crosstab(x, data[\"salary\"], normalize=\"index\").sort_values(\n",
    "        by=\" >50K\", ascending=False\n",
    "    )\n",
    "    tab.plot(kind=\"bar\", stacked=True, figsize=(17, 7))\n",
    "    plt.legend(\n",
    "        loc=\"lower left\", frameon=False,\n",
    "    )\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68dee44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"def stacked_barplot(data, predictor, target):\\n    \\\"\\\"\\\"\\n    Print the category counts and plot a stacked bar chart\\n\\n    data: dataframe\\n    predictor: independent variable\\n    target: target variable\\n    \\\"\\\"\\\"\\n    count = data[predictor].nunique()\\n    sorter = data[target].value_counts().index[-1]\\n    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\\n        by=sorter, ascending=False\\n    )\\n    print(tab1)\\n    print(\\\"-\\\" * 120)\\n    tab = pd.crosstab(data[predictor], data[target], normalize=\\\"index\\\").sort_values(\\n        by=sorter, ascending=False\\n    )\\n    tab.plot(kind=\\\"bar\\\", stacked=True, figsize=(count + 5, 5))\\n    plt.legend(\\n        loc=\\\"lower left\\\", frameon=False,\\n    )\\n    plt.legend(loc=\\\"upper left\\\", bbox_to_anchor=(1, 1))\\n    plt.show()\";\n",
       "                var nbb_formatted_code = \"def stacked_barplot(data, predictor, target):\\n    \\\"\\\"\\\"\\n    Print the category counts and plot a stacked bar chart\\n\\n    data: dataframe\\n    predictor: independent variable\\n    target: target variable\\n    \\\"\\\"\\\"\\n    count = data[predictor].nunique()\\n    sorter = data[target].value_counts().index[-1]\\n    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\\n        by=sorter, ascending=False\\n    )\\n    print(tab1)\\n    print(\\\"-\\\" * 120)\\n    tab = pd.crosstab(data[predictor], data[target], normalize=\\\"index\\\").sort_values(\\n        by=sorter, ascending=False\\n    )\\n    tab.plot(kind=\\\"bar\\\", stacked=True, figsize=(count + 5, 5))\\n    plt.legend(\\n        loc=\\\"lower left\\\", frameon=False,\\n    )\\n    plt.legend(loc=\\\"upper left\\\", bbox_to_anchor=(1, 1))\\n    plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def stacked_barplot(data, predictor, target):\n",
    "    \"\"\"\n",
    "    Print the category counts and plot a stacked bar chart\n",
    "\n",
    "    data: dataframe\n",
    "    predictor: independent variable\n",
    "    target: target variable\n",
    "    \"\"\"\n",
    "    count = data[predictor].nunique()\n",
    "    sorter = data[target].value_counts().index[-1]\n",
    "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 120)\n",
    "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 5, 5))\n",
    "    plt.legend(\n",
    "        loc=\"lower left\", frameon=False,\n",
    "    )\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "606da266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"## Function to create confusion matrix\\ndef make_confusion_matrix(model, y_actual, Xvars, labels=[1, 0]):\\n    \\\"\\\"\\\"\\n    model : classifier to predict values of X\\n    y_actual : ground truth  \\n    \\n    \\\"\\\"\\\"\\n    y_predict = model.predict(Xvars)\\n    cm = metrics.confusion_matrix(y_actual, y_predict, labels=[0, 1])\\n    df_cm = pd.DataFrame(\\n        cm,\\n        index=[i for i in [\\\"Actual - No\\\", \\\"Actual - Yes\\\"]],\\n        columns=[i for i in [\\\"Predicted - No\\\", \\\"Predicted - Yes\\\"]],\\n    )\\n    group_counts = [\\\"{0:0.0f}\\\".format(value) for value in cm.flatten()]\\n    group_percentages = [\\\"{0:.2%}\\\".format(value) for value in cm.flatten() / np.sum(cm)]\\n    labels = [f\\\"{v1}\\\\n{v2}\\\" for v1, v2 in zip(group_counts, group_percentages)]\\n    labels = np.asarray(labels).reshape(2, 2)\\n    plt.figure(figsize=(10, 7))\\n    sns.heatmap(df_cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\";\n",
       "                var nbb_formatted_code = \"## Function to create confusion matrix\\ndef make_confusion_matrix(model, y_actual, Xvars, labels=[1, 0]):\\n    \\\"\\\"\\\"\\n    model : classifier to predict values of X\\n    y_actual : ground truth  \\n    \\n    \\\"\\\"\\\"\\n    y_predict = model.predict(Xvars)\\n    cm = metrics.confusion_matrix(y_actual, y_predict, labels=[0, 1])\\n    df_cm = pd.DataFrame(\\n        cm,\\n        index=[i for i in [\\\"Actual - No\\\", \\\"Actual - Yes\\\"]],\\n        columns=[i for i in [\\\"Predicted - No\\\", \\\"Predicted - Yes\\\"]],\\n    )\\n    group_counts = [\\\"{0:0.0f}\\\".format(value) for value in cm.flatten()]\\n    group_percentages = [\\\"{0:.2%}\\\".format(value) for value in cm.flatten() / np.sum(cm)]\\n    labels = [f\\\"{v1}\\\\n{v2}\\\" for v1, v2 in zip(group_counts, group_percentages)]\\n    labels = np.asarray(labels).reshape(2, 2)\\n    plt.figure(figsize=(10, 7))\\n    sns.heatmap(df_cm, annot=labels, fmt=\\\"\\\")\\n    plt.ylabel(\\\"True label\\\")\\n    plt.xlabel(\\\"Predicted label\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Function to create confusion matrix\n",
    "def make_confusion_matrix(model, y_actual, Xvars, labels=[1, 0]):\n",
    "    \"\"\"\n",
    "    model : classifier to predict values of X\n",
    "    y_actual : ground truth  \n",
    "    \n",
    "    \"\"\"\n",
    "    y_predict = model.predict(Xvars)\n",
    "    cm = metrics.confusion_matrix(y_actual, y_predict, labels=[0, 1])\n",
    "    df_cm = pd.DataFrame(\n",
    "        cm,\n",
    "        index=[i for i in [\"Actual - No\", \"Actual - Yes\"]],\n",
    "        columns=[i for i in [\"Predicted - No\", \"Predicted - Yes\"]],\n",
    "    )\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten() / np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df_cm, annot=labels, fmt=\"\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27fefb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# function to compute adjusted R-squared\\ndef adj_r2_score(predictors, targets, predictions):\\n    r2 = r2_score(targets, predictions)\\n    n = predictors.shape[0]\\n    k = predictors.shape[1]\\n    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\\n\\n\\n# function to compute MAPE\\ndef mape_score(targets, predictions):\\n    return np.mean(np.abs(targets - predictions) / targets) * 100\\n\\n\\n# function to compute different metrics to check performance of a regression model\\ndef model_performance_regression(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check regression model performance\\n\\n    model: regressor\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n\\n    # predicting using the independent variables\\n    pred = model.predict(predictors)\\n\\n    r2 = r2_score(target, pred)  # to compute R-squared\\n    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\\n    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\\n    mae = mean_absolute_error(target, pred)  # to compute MAE\\n    mape = mape_score(target, pred)  # to compute MAPE\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\n            \\\"RMSE\\\": rmse,\\n            \\\"MAE\\\": mae,\\n            \\\"R-squared\\\": r2,\\n            \\\"Adj. R-squared\\\": adjr2,\\n            \\\"MAPE\\\": mape,\\n        },\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
       "                var nbb_formatted_code = \"# function to compute adjusted R-squared\\ndef adj_r2_score(predictors, targets, predictions):\\n    r2 = r2_score(targets, predictions)\\n    n = predictors.shape[0]\\n    k = predictors.shape[1]\\n    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\\n\\n\\n# function to compute MAPE\\ndef mape_score(targets, predictions):\\n    return np.mean(np.abs(targets - predictions) / targets) * 100\\n\\n\\n# function to compute different metrics to check performance of a regression model\\ndef model_performance_regression(model, predictors, target):\\n    \\\"\\\"\\\"\\n    Function to compute different metrics to check regression model performance\\n\\n    model: regressor\\n    predictors: independent variables\\n    target: dependent variable\\n    \\\"\\\"\\\"\\n\\n    # predicting using the independent variables\\n    pred = model.predict(predictors)\\n\\n    r2 = r2_score(target, pred)  # to compute R-squared\\n    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\\n    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\\n    mae = mean_absolute_error(target, pred)  # to compute MAE\\n    mape = mape_score(target, pred)  # to compute MAPE\\n\\n    # creating a dataframe of metrics\\n    df_perf = pd.DataFrame(\\n        {\\n            \\\"RMSE\\\": rmse,\\n            \\\"MAE\\\": mae,\\n            \\\"R-squared\\\": r2,\\n            \\\"Adj. R-squared\\\": adjr2,\\n            \\\"MAPE\\\": mape,\\n        },\\n        index=[0],\\n    )\\n\\n    return df_perf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function to compute adjusted R-squared\n",
    "def adj_r2_score(predictors, targets, predictions):\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    n = predictors.shape[0]\n",
    "    k = predictors.shape[1]\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "\n",
    "# function to compute MAPE\n",
    "def mape_score(targets, predictions):\n",
    "    return np.mean(np.abs(targets - predictions) / targets) * 100\n",
    "\n",
    "\n",
    "# function to compute different metrics to check performance of a regression model\n",
    "def model_performance_regression(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check regression model performance\n",
    "\n",
    "    model: regressor\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    r2 = r2_score(target, pred)  # to compute R-squared\n",
    "    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\n",
    "    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\n",
    "    mae = mean_absolute_error(target, pred)  # to compute MAE\n",
    "    mape = mape_score(target, pred)  # to compute MAPE\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R-squared\": r2,\n",
    "            \"Adj. R-squared\": adjr2,\n",
    "            \"MAPE\": mape,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "367e62de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"def objectColumns(x, objType):\\n    cols = []\\n    for col in x.columns[x.dtypes == objType]:\\n        cols.append(col)\\n    return cols\\n\\n\\ndef getValueCounts(x, objType, itemsToDisplay):\\n    for colname in objectColumns(x, objType):\\n        val_counts = x[colname].value_counts(dropna=False)\\n        print(val_counts[:itemsToDisplay])\\n        if len(val_counts) > itemsToDisplay:\\n            print(\\n                f\\\"Only displaying first {itemsToDisplay} of {len(val_counts)} unique values.\\\\n\\\"\\n            )\\n        print(\\\"\\\\n\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"def objectColumns(x, objType):\\n    cols = []\\n    for col in x.columns[x.dtypes == objType]:\\n        cols.append(col)\\n    return cols\\n\\n\\ndef getValueCounts(x, objType, itemsToDisplay):\\n    for colname in objectColumns(x, objType):\\n        val_counts = x[colname].value_counts(dropna=False)\\n        print(val_counts[:itemsToDisplay])\\n        if len(val_counts) > itemsToDisplay:\\n            print(\\n                f\\\"Only displaying first {itemsToDisplay} of {len(val_counts)} unique values.\\\\n\\\"\\n            )\\n        print(\\\"\\\\n\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def objectColumns(x, objType):\n",
    "    cols = []\n",
    "    for col in x.columns[x.dtypes == objType]:\n",
    "        cols.append(col)\n",
    "    return cols\n",
    "\n",
    "\n",
    "def getValueCounts(x, objType, itemsToDisplay):\n",
    "    for colname in objectColumns(x, objType):\n",
    "        val_counts = x[colname].value_counts(dropna=False)\n",
    "        print(val_counts[:itemsToDisplay])\n",
    "        if len(val_counts) > itemsToDisplay:\n",
    "            print(\n",
    "                f\"Only displaying first {itemsToDisplay} of {len(val_counts)} unique values.\\n\"\n",
    "            )\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f925a84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"def getNullColumnsandTypes(df):\\n    nulldf = pd.DataFrame(\\n        df.isna().sum().sort_values(ascending=False), columns=[\\\"MissingCounts\\\"]\\n    )\\n    nulldf[\\\"colDType\\\"] = [(df[(col)].dtypes) for col in nulldf.index]\\n    return nulldf\";\n",
       "                var nbb_formatted_code = \"def getNullColumnsandTypes(df):\\n    nulldf = pd.DataFrame(\\n        df.isna().sum().sort_values(ascending=False), columns=[\\\"MissingCounts\\\"]\\n    )\\n    nulldf[\\\"colDType\\\"] = [(df[(col)].dtypes) for col in nulldf.index]\\n    return nulldf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getNullColumnsandTypes(df):\n",
    "    nulldf = pd.DataFrame(\n",
    "        df.isna().sum().sort_values(ascending=False), columns=[\"MissingCounts\"]\n",
    "    )\n",
    "    nulldf[\"colDType\"] = [(df[(col)].dtypes) for col in nulldf.index]\n",
    "    return nulldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09f9a94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"def convert2int(df, colsList):\\n    for feature in colsList:\\n        df[feature] = df[feature].astype(str).astype(int)\\n    return df\";\n",
       "                var nbb_formatted_code = \"def convert2int(df, colsList):\\n    for feature in colsList:\\n        df[feature] = df[feature].astype(str).astype(int)\\n    return df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert2int(df, colsList):\n",
    "    for feature in colsList:\n",
    "        df[feature] = df[feature].astype(str).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df8c07b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"def convert2datetime(df, colsList):\\n    for feature in colsList:\\n        df[feature] = pd.to_datetime(\\n            df[feature],\\n            format=\\\"%Y%m%d\\\",\\n            errors=\\\"ignore\\\",\\n            utc=True,\\n            #             infer_datetime_format=True\\n        )\\n    return df\";\n",
       "                var nbb_formatted_code = \"def convert2datetime(df, colsList):\\n    for feature in colsList:\\n        df[feature] = pd.to_datetime(\\n            df[feature],\\n            format=\\\"%Y%m%d\\\",\\n            errors=\\\"ignore\\\",\\n            utc=True,\\n            #             infer_datetime_format=True\\n        )\\n    return df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert2datetime(df, colsList):\n",
    "    for feature in colsList:\n",
    "        df[feature] = pd.to_datetime(\n",
    "            df[feature],\n",
    "            format=\"%Y%m%d\",\n",
    "            errors=\"ignore\",\n",
    "            utc=True,\n",
    "            #             infer_datetime_format=True\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a7cba56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"def convert2Category(creditData):\\n    for feature in creditData.columns:  # Loop through all columns in the dataframe\\n        if (\\n            creditData[feature].dtype == \\\"object\\\"\\n        ):  # Only apply for columns with categorical strings\\n            creditData[feature] = pd.Categorical(\\n                creditData[feature]\\n            )  # Replace strings with an integer\\n    return creditData\";\n",
       "                var nbb_formatted_code = \"def convert2Category(creditData):\\n    for feature in creditData.columns:  # Loop through all columns in the dataframe\\n        if (\\n            creditData[feature].dtype == \\\"object\\\"\\n        ):  # Only apply for columns with categorical strings\\n            creditData[feature] = pd.Categorical(\\n                creditData[feature]\\n            )  # Replace strings with an integer\\n    return creditData\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert2Category(creditData):\n",
    "    for feature in creditData.columns:  # Loop through all columns in the dataframe\n",
    "        if (\n",
    "            creditData[feature].dtype == \"object\"\n",
    "        ):  # Only apply for columns with categorical strings\n",
    "            creditData[feature] = pd.Categorical(\n",
    "                creditData[feature]\n",
    "            )  # Replace strings with an integer\n",
    "    return creditData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f61f1f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"def treat_outliers(df, col):\\n    \\\"\\\"\\\"\\n    Treats outliers in a variable\\n\\n    df: dataframe\\n    col: dataframe column\\n    \\\"\\\"\\\"\\n    Q1 = df[col].quantile(0.25)  # 25th quantile\\n    Q3 = df[col].quantile(0.75)  # 75th quantile\\n    IQR = Q3 - Q1\\n    Lower_Whisker = Q1 - 1.5 * IQR\\n    Upper_Whisker = Q3 + 1.5 * IQR\\n\\n    # all the values smaller than Lower_Whisker will be assigned the value of Lower_Whisker\\n    # all the values greater than Upper_Whisker will be assigned the value of Upper_Whisker\\n    df[col] = np.clip(df[col], Lower_Whisker, Upper_Whisker)\\n\\n    return df\\n\\n\\ndef treat_outliers_all(df, col_list):\\n    \\\"\\\"\\\"\\n    Treat outliers in a list of variables\\n\\n    df: dataframe\\n    col_list: list of dataframe columns\\n    \\\"\\\"\\\"\\n    for c in col_list:\\n        df = treat_outliers(df, c)\\n\\n    return df\\n\\n\\ndef plotForSkewness(x):\\n    # creating a list of non-tag columns\\n    dist_cols = [item for item in x.select_dtypes(include=np.number).columns]\\n    # let's plot a histogram of all non-tag columns\\n    plt.figure(figsize=(15, 30))\\n    for i in range(len(dist_cols)):\\n        plt.subplot(9, 3, i + 1)\\n        plt.hist(x[dist_cols[i]], bins=50)\\n        plt.tight_layout()\\n        plt.xlabel(dist_cols[i], fontsize=15)\\n        plt.show()\\n    return dist_cols\\n\\n\\n# get List of all Object Columns in a given dataframe\\ndef objectColumns(x, objType):\\n    cols = []\\n    for col in x.columns[x.dtypes == objType]:\\n        cols.append(col)\\n    return cols\\n\\n\\ndef getValueCounts(x, objType, itemsToDisplay):\\n    for colname in objectColumns(x, objType):\\n        val_counts = x[colname].value_counts(dropna=False)\\n        print(val_counts[:itemsToDisplay])\\n        if len(val_counts) > itemsToDisplay:\\n            print(\\n                f\\\"Only displaying first {itemsToDisplay} of {len(val_counts)} unique values.\\\\n\\\"\\n            )\\n        print(\\\"\\\\n\\\\n\\\")\\n\\n\\ndef histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\\n    \\\"\\\"\\\"\\n    Boxplot and histogram combined\\n\\n    data: dataframe\\n    feature: dataframe column\\n    figsize: size of figure (default (12,7))\\n    kde: whether to show the density curve (default False)\\n    bins: number of bins for histogram (default None)\\n    \\\"\\\"\\\"\\n    f2, (ax_box2, ax_hist2) = plt.subplots(\\n        nrows=2,  # Number of rows of the subplot grid= 2\\n        sharex=True,  # x-axis will be shared among all subplots\\n        gridspec_kw={\\\"height_ratios\\\": (0.25, 0.75)},\\n        figsize=figsize,\\n    )  # creating the 2 subplots\\n    sns.boxplot(\\n        data=data, x=feature, ax=ax_box2, showmeans=True, color=\\\"violet\\\"\\n    )  # boxplot will be created and a star will indicate the mean value of the column\\n    sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\\\"winter\\\"\\n    ) if bins else sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2\\n    )  # For histogram\\n    ax_hist2.axvline(\\n        data[feature].mean(), color=\\\"green\\\", linestyle=\\\"--\\\"\\n    )  # Add mean to the histogram\\n    ax_hist2.axvline(\\n        data[feature].median(), color=\\\"black\\\", linestyle=\\\"-\\\"\\n    )  # Add median to the histogram\\n\\n\\ndef labeled_barplot(data, feature, perc=False, n=None):\\n    \\\"\\\"\\\"\\n    Barplot with percentage at the top\\n\\n    data: dataframe\\n    feature: dataframe column\\n    perc: whether to display percentages instead of count (default is False)\\n    n: displays the top n category levels (default is None, i.e., display all levels)\\n    \\\"\\\"\\\"\\n\\n    total = len(data[feature])  # length of the column\\n    count = data[feature].nunique()\\n    if n is None:\\n        plt.figure(figsize=(count + 1, 5))\\n    else:\\n        plt.figure(figsize=(n + 1, 5))\\n\\n    plt.xticks(rotation=90, fontsize=15)\\n    ax = sns.countplot(\\n        data=data,\\n        x=feature,\\n        palette=\\\"Paired\\\",\\n        order=data[feature].value_counts().index[:n].sort_values(),\\n    )\\n\\n    for p in ax.patches:\\n        if perc == True:\\n            label = \\\"{:.1f}%\\\".format(\\n                100 * p.get_height() / total\\n            )  # percentage of each class of the category\\n        else:\\n            label = p.get_height()  # count of each level of the category\\n\\n        x = p.get_x() + p.get_width() / 2  # width of the plot\\n        y = p.get_height()  # height of the plot\\n\\n        ax.annotate(\\n            label,\\n            (x, y),\\n            ha=\\\"center\\\",\\n            va=\\\"center\\\",\\n            size=12,\\n            xytext=(0, 5),\\n            textcoords=\\\"offset points\\\",\\n        )  # annotate the percentage\\n\\n    plt.show()  # show the plot\";\n",
       "                var nbb_formatted_code = \"def treat_outliers(df, col):\\n    \\\"\\\"\\\"\\n    Treats outliers in a variable\\n\\n    df: dataframe\\n    col: dataframe column\\n    \\\"\\\"\\\"\\n    Q1 = df[col].quantile(0.25)  # 25th quantile\\n    Q3 = df[col].quantile(0.75)  # 75th quantile\\n    IQR = Q3 - Q1\\n    Lower_Whisker = Q1 - 1.5 * IQR\\n    Upper_Whisker = Q3 + 1.5 * IQR\\n\\n    # all the values smaller than Lower_Whisker will be assigned the value of Lower_Whisker\\n    # all the values greater than Upper_Whisker will be assigned the value of Upper_Whisker\\n    df[col] = np.clip(df[col], Lower_Whisker, Upper_Whisker)\\n\\n    return df\\n\\n\\ndef treat_outliers_all(df, col_list):\\n    \\\"\\\"\\\"\\n    Treat outliers in a list of variables\\n\\n    df: dataframe\\n    col_list: list of dataframe columns\\n    \\\"\\\"\\\"\\n    for c in col_list:\\n        df = treat_outliers(df, c)\\n\\n    return df\\n\\n\\ndef plotForSkewness(x):\\n    # creating a list of non-tag columns\\n    dist_cols = [item for item in x.select_dtypes(include=np.number).columns]\\n    # let's plot a histogram of all non-tag columns\\n    plt.figure(figsize=(15, 30))\\n    for i in range(len(dist_cols)):\\n        plt.subplot(9, 3, i + 1)\\n        plt.hist(x[dist_cols[i]], bins=50)\\n        plt.tight_layout()\\n        plt.xlabel(dist_cols[i], fontsize=15)\\n        plt.show()\\n    return dist_cols\\n\\n\\n# get List of all Object Columns in a given dataframe\\ndef objectColumns(x, objType):\\n    cols = []\\n    for col in x.columns[x.dtypes == objType]:\\n        cols.append(col)\\n    return cols\\n\\n\\ndef getValueCounts(x, objType, itemsToDisplay):\\n    for colname in objectColumns(x, objType):\\n        val_counts = x[colname].value_counts(dropna=False)\\n        print(val_counts[:itemsToDisplay])\\n        if len(val_counts) > itemsToDisplay:\\n            print(\\n                f\\\"Only displaying first {itemsToDisplay} of {len(val_counts)} unique values.\\\\n\\\"\\n            )\\n        print(\\\"\\\\n\\\\n\\\")\\n\\n\\ndef histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\\n    \\\"\\\"\\\"\\n    Boxplot and histogram combined\\n\\n    data: dataframe\\n    feature: dataframe column\\n    figsize: size of figure (default (12,7))\\n    kde: whether to show the density curve (default False)\\n    bins: number of bins for histogram (default None)\\n    \\\"\\\"\\\"\\n    f2, (ax_box2, ax_hist2) = plt.subplots(\\n        nrows=2,  # Number of rows of the subplot grid= 2\\n        sharex=True,  # x-axis will be shared among all subplots\\n        gridspec_kw={\\\"height_ratios\\\": (0.25, 0.75)},\\n        figsize=figsize,\\n    )  # creating the 2 subplots\\n    sns.boxplot(\\n        data=data, x=feature, ax=ax_box2, showmeans=True, color=\\\"violet\\\"\\n    )  # boxplot will be created and a star will indicate the mean value of the column\\n    sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\\\"winter\\\"\\n    ) if bins else sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2\\n    )  # For histogram\\n    ax_hist2.axvline(\\n        data[feature].mean(), color=\\\"green\\\", linestyle=\\\"--\\\"\\n    )  # Add mean to the histogram\\n    ax_hist2.axvline(\\n        data[feature].median(), color=\\\"black\\\", linestyle=\\\"-\\\"\\n    )  # Add median to the histogram\\n\\n\\ndef labeled_barplot(data, feature, perc=False, n=None):\\n    \\\"\\\"\\\"\\n    Barplot with percentage at the top\\n\\n    data: dataframe\\n    feature: dataframe column\\n    perc: whether to display percentages instead of count (default is False)\\n    n: displays the top n category levels (default is None, i.e., display all levels)\\n    \\\"\\\"\\\"\\n\\n    total = len(data[feature])  # length of the column\\n    count = data[feature].nunique()\\n    if n is None:\\n        plt.figure(figsize=(count + 1, 5))\\n    else:\\n        plt.figure(figsize=(n + 1, 5))\\n\\n    plt.xticks(rotation=90, fontsize=15)\\n    ax = sns.countplot(\\n        data=data,\\n        x=feature,\\n        palette=\\\"Paired\\\",\\n        order=data[feature].value_counts().index[:n].sort_values(),\\n    )\\n\\n    for p in ax.patches:\\n        if perc == True:\\n            label = \\\"{:.1f}%\\\".format(\\n                100 * p.get_height() / total\\n            )  # percentage of each class of the category\\n        else:\\n            label = p.get_height()  # count of each level of the category\\n\\n        x = p.get_x() + p.get_width() / 2  # width of the plot\\n        y = p.get_height()  # height of the plot\\n\\n        ax.annotate(\\n            label,\\n            (x, y),\\n            ha=\\\"center\\\",\\n            va=\\\"center\\\",\\n            size=12,\\n            xytext=(0, 5),\\n            textcoords=\\\"offset points\\\",\\n        )  # annotate the percentage\\n\\n    plt.show()  # show the plot\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def treat_outliers(df, col):\n",
    "    \"\"\"\n",
    "    Treats outliers in a variable\n",
    "\n",
    "    df: dataframe\n",
    "    col: dataframe column\n",
    "    \"\"\"\n",
    "    Q1 = df[col].quantile(0.25)  # 25th quantile\n",
    "    Q3 = df[col].quantile(0.75)  # 75th quantile\n",
    "    IQR = Q3 - Q1\n",
    "    Lower_Whisker = Q1 - 1.5 * IQR\n",
    "    Upper_Whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "    # all the values smaller than Lower_Whisker will be assigned the value of Lower_Whisker\n",
    "    # all the values greater than Upper_Whisker will be assigned the value of Upper_Whisker\n",
    "    df[col] = np.clip(df[col], Lower_Whisker, Upper_Whisker)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def treat_outliers_all(df, col_list):\n",
    "    \"\"\"\n",
    "    Treat outliers in a list of variables\n",
    "\n",
    "    df: dataframe\n",
    "    col_list: list of dataframe columns\n",
    "    \"\"\"\n",
    "    for c in col_list:\n",
    "        df = treat_outliers(df, c)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def plotForSkewness(x):\n",
    "    # creating a list of non-tag columns\n",
    "    dist_cols = [item for item in x.select_dtypes(include=np.number).columns]\n",
    "    # let's plot a histogram of all non-tag columns\n",
    "    plt.figure(figsize=(15, 30))\n",
    "    for i in range(len(dist_cols)):\n",
    "        plt.subplot(9, 3, i + 1)\n",
    "        plt.hist(x[dist_cols[i]], bins=50)\n",
    "        plt.tight_layout()\n",
    "        plt.xlabel(dist_cols[i], fontsize=15)\n",
    "        plt.show()\n",
    "    return dist_cols\n",
    "\n",
    "\n",
    "# get List of all Object Columns in a given dataframe\n",
    "def objectColumns(x, objType):\n",
    "    cols = []\n",
    "    for col in x.columns[x.dtypes == objType]:\n",
    "        cols.append(col)\n",
    "    return cols\n",
    "\n",
    "\n",
    "def getValueCounts(x, objType, itemsToDisplay):\n",
    "    for colname in objectColumns(x, objType):\n",
    "        val_counts = x[colname].value_counts(dropna=False)\n",
    "        print(val_counts[:itemsToDisplay])\n",
    "        if len(val_counts) > itemsToDisplay:\n",
    "            print(\n",
    "                f\"Only displaying first {itemsToDisplay} of {len(val_counts)} unique values.\\n\"\n",
    "            )\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to show the density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram\n",
    "\n",
    "\n",
    "def labeled_barplot(data, feature, perc=False, n=None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize=(count + 1, 5))\n",
    "    else:\n",
    "        plt.figure(figsize=(n + 1, 5))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        order=data[feature].value_counts().index[:n].sort_values(),\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc == True:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
    "        y = p.get_height()  # height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )  # annotate the percentage\n",
    "\n",
    "    plt.show()  # show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "843630ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"def multipleHistPlots(df1):\\n    dist_cols = [item for item in df1.select_dtypes(include=np.number).columns]\\n    plt.figure(figsize=(15, 30))\\n    for i in range(len(dist_cols)):\\n        plt.subplot(9, 3, i + 1)\\n        plt.hist(df1[dist_cols[i]], bins=50, density=True)\\n        plt.tight_layout()\\n        plt.xlabel(dist_cols[i], fontsize=15)\\n\\n    plt.show()\";\n",
       "                var nbb_formatted_code = \"def multipleHistPlots(df1):\\n    dist_cols = [item for item in df1.select_dtypes(include=np.number).columns]\\n    plt.figure(figsize=(15, 30))\\n    for i in range(len(dist_cols)):\\n        plt.subplot(9, 3, i + 1)\\n        plt.hist(df1[dist_cols[i]], bins=50, density=True)\\n        plt.tight_layout()\\n        plt.xlabel(dist_cols[i], fontsize=15)\\n\\n    plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def multipleHistPlots(df1):\n",
    "    dist_cols = [item for item in df1.select_dtypes(include=np.number).columns]\n",
    "    plt.figure(figsize=(15, 30))\n",
    "    for i in range(len(dist_cols)):\n",
    "        plt.subplot(9, 3, i + 1)\n",
    "        plt.hist(df1[dist_cols[i]], bins=50, density=True)\n",
    "        plt.tight_layout()\n",
    "        plt.xlabel(dist_cols[i], fontsize=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2edd6591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# creating a list of numeric columns\\ndef mulipleBoxPlots(df2):\\n    out_cols = [item for item in df2.select_dtypes(include=np.number)]\\n\\n    plt.figure(figsize=(15, 35))\\n\\n    for i, variable in enumerate(new_dist_cols):\\n        plt.subplot(9, 3, i + 1)\\n        plt.boxplot(df2[variable], whis=1.5)\\n        plt.tight_layout()\\n        plt.title(variable)\\n\\n    plt.show()\";\n",
       "                var nbb_formatted_code = \"# creating a list of numeric columns\\ndef mulipleBoxPlots(df2):\\n    out_cols = [item for item in df2.select_dtypes(include=np.number)]\\n\\n    plt.figure(figsize=(15, 35))\\n\\n    for i, variable in enumerate(new_dist_cols):\\n        plt.subplot(9, 3, i + 1)\\n        plt.boxplot(df2[variable], whis=1.5)\\n        plt.tight_layout()\\n        plt.title(variable)\\n\\n    plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating a list of numeric columns\n",
    "def mulipleBoxPlots(df2):\n",
    "    out_cols = [item for item in df2.select_dtypes(include=np.number)]\n",
    "\n",
    "    plt.figure(figsize=(15, 35))\n",
    "\n",
    "    for i, variable in enumerate(new_dist_cols):\n",
    "        plt.subplot(9, 3, i + 1)\n",
    "        plt.boxplot(df2[variable], whis=1.5)\n",
    "        plt.tight_layout()\n",
    "        plt.title(variable)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc28081f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"def getVIFSeries(x_train):\\n    return pd.DataFrame(\\n        [variance_inflation_factor(x_train.values, i) for i in range(x_train.shape[1])],\\n        index=x_train.columns,\\n    )\";\n",
       "                var nbb_formatted_code = \"def getVIFSeries(x_train):\\n    return pd.DataFrame(\\n        [variance_inflation_factor(x_train.values, i) for i in range(x_train.shape[1])],\\n        index=x_train.columns,\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getVIFSeries(x_train):\n",
    "    return pd.DataFrame(\n",
    "        [variance_inflation_factor(x_train.values, i) for i in range(x_train.shape[1])],\n",
    "        index=x_train.columns,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c9f2d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"def printAdjustedRSquaresafterColumnDrop(x_tr, y_tr, colNametoDrop):\\n    X_tr2 = x_tr.drop([colNametoDrop], axis=1)\\n    olsSumPrev = sm.OLS(y_tr, x_tr).fit()\\n    olsSum = sm.OLS(y_tr, X_tr2).fit()\\n    print(f'R-Squared:\\\\nPrevious = {np.round(olsSumPrev.rsquared, 3)}\\\\tAfter deleting {colNametoDrop} = {np.round(olsSum.rsquared, 3)}\\\\nAdjusted R-Square:\\\\nPrevious = {np.round(olsSumPrev.rsquared_adj, 3)}\\\\tAfter deleting {colNametoDrop} = {np.round(olsSum.rsquared_adj, 3)}\\\\n'\\n    )\\n    return (X_tr2, olsSum)\";\n",
       "                var nbb_formatted_code = \"def printAdjustedRSquaresafterColumnDrop(x_tr, y_tr, colNametoDrop):\\n    X_tr2 = x_tr.drop([colNametoDrop], axis=1)\\n    olsSumPrev = sm.OLS(y_tr, x_tr).fit()\\n    olsSum = sm.OLS(y_tr, X_tr2).fit()\\n    print(\\n        f\\\"R-Squared:\\\\nPrevious = {np.round(olsSumPrev.rsquared, 3)}\\\\tAfter deleting {colNametoDrop} = {np.round(olsSum.rsquared, 3)}\\\\nAdjusted R-Square:\\\\nPrevious = {np.round(olsSumPrev.rsquared_adj, 3)}\\\\tAfter deleting {colNametoDrop} = {np.round(olsSum.rsquared_adj, 3)}\\\\n\\\"\\n    )\\n    return (X_tr2, olsSum)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def printAdjustedRSquaresafterColumnDrop(x_tr, y_tr, colNametoDrop):\n",
    "    X_tr2 = x_tr.drop([colNametoDrop], axis=1)\n",
    "    olsSumPrev = sm.OLS(y_tr, x_tr).fit()\n",
    "    olsSum = sm.OLS(y_tr, X_tr2).fit()\n",
    "    print(f'R-Squared:\\nPrevious = {np.round(olsSumPrev.rsquared, 3)}\\tAfter deleting {colNametoDrop} = {np.round(olsSum.rsquared, 3)}\\nAdjusted R-Square:\\nPrevious = {np.round(olsSumPrev.rsquared_adj, 3)}\\tAfter deleting {colNametoDrop} = {np.round(olsSum.rsquared_adj, 3)}\\n'\n",
    "    )\n",
    "    return (X_tr2, olsSum)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
